{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, Headers and Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CACHED = True\n",
    "\n",
    "SEQUENCE_LEN = 50\n",
    "EMBEDDING_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepares the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words:\n",
      "[u'Pierre', u'Vinken', u',', u'61', u'years', u'old', u',', u'will', u'join', u'the', u'board', u'as', u'a', u'nonexecutive', u'director']\n",
      "Total: 100676\n",
      "Distinct: 12408\n",
      "\n",
      "All tags:\n",
      "[u'NOUN', u'NOUN', u'.', u'NUM', u'NOUN', u'ADJ', u'.', u'VERB', u'VERB', u'DET', u'NOUN', u'ADP', u'DET', u'ADJ', u'NOUN']\n",
      "Total: 100676\n",
      "Distinct: 12\n"
     ]
    }
   ],
   "source": [
    "tagged_words = list(treebank.tagged_words(tagset='universal'))\n",
    "\n",
    "all_words = [w[0] for w in tagged_words]\n",
    "all_tags = [w[1] for w in tagged_words]\n",
    "\n",
    "distinct_words = list(set(all_words))\n",
    "distinct_tags = list(set(all_tags))\n",
    "\n",
    "n_words = len(distinct_words)\n",
    "n_tags = len(distinct_tags)\n",
    "\n",
    "print 'All words:'\n",
    "print all_words[:15]\n",
    "print 'Total:', len(all_words)\n",
    "print 'Distinct:', len(distinct_words)\n",
    "print  ''\n",
    "print 'All tags:'\n",
    "print all_tags[:15]\n",
    "print 'Total:', len(all_tags)\n",
    "print 'Distinct:', len(distinct_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = {w:i for (i,w) in enumerate(distinct_words)}\n",
    "idx2word = {v:k for (k,v) in word2idx.items()}\n",
    "\n",
    "tag2idx = {w:i for (i,w) in enumerate(distinct_tags)}\n",
    "idx2tag = {v:k for (k,v) in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Training Set: 80540\n",
      "Size Testing Set: 20136\n"
     ]
    }
   ],
   "source": [
    "N_train = int(len(all_words) * .8)\n",
    "N_test  = len(all_words) - N_train\n",
    "print 'Size Training Set:', N_train\n",
    "print 'Size Testing Set:', N_test\n",
    "\n",
    "words_train = [word2idx[w] for w in all_words[:N_train]]\n",
    "words_test = [word2idx[w] for w in all_words[N_train:]]\n",
    "\n",
    "tags_train = [tag2idx[w] for w in all_tags[:N_train]]\n",
    "tags_test = [tag2idx[w] for w in all_tags[N_train:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:\n",
      "(80490, 50)\n",
      "X test shape:\n",
      "(20086, 50)\n",
      "X train sample:\n",
      "[[12196  4523  6347 10526   964   638  6347 12148  6949  3674  3698  1492\n",
      "   4820 11003 10612 10085  7948   519  5525  4523  6669 11193 10722  4938\n",
      "  10676  6347  3674  7075  1997  7137   519  8996 11911  6347  9862   964\n",
      "    638 10371  1271 11193 10722  2254 12046  4628 12150  6347  3790  8568\n",
      "   4449  4820]\n",
      " [ 4523  6347 10526   964   638  6347 12148  6949  3674  3698  1492  4820\n",
      "  11003 10612 10085  7948   519  5525  4523  6669 11193 10722  4938 10676\n",
      "   6347  3674  7075  1997  7137   519  8996 11911  6347  9862   964   638\n",
      "  10371  1271 11193 10722  2254 12046  4628 12150  6347  3790  8568  4449\n",
      "   4820 11003]]\n",
      "y train shape:\n",
      "(80490, 50, 12)\n",
      "y test shape:\n",
      "(20086, 50, 12)\n",
      "y train sample:\n",
      "[[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  1.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  1.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "def vectorize(seq, window_size):\n",
    "    out = []\n",
    "    for i in range(len(seq) - window_size):\n",
    "        out.append(seq[i:i+window_size])\n",
    "    out = np.array(out)\n",
    "    return out\n",
    "\n",
    "X_train = vectorize(words_train, SEQUENCE_LEN)\n",
    "X_test  = vectorize(words_test, SEQUENCE_LEN)\n",
    "\n",
    "y_train = vectorize(tags_train, SEQUENCE_LEN)\n",
    "y_test = vectorize(tags_test, SEQUENCE_LEN)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, n_tags)\n",
    "y_train = np.reshape(y_train, (X_train.shape[0], X_train.shape[1], n_tags))\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, n_tags)\n",
    "y_test = np.reshape(y_test, (X_test.shape[0], X_test.shape[1], n_tags))\n",
    "\n",
    "print 'X train shape:'\n",
    "print X_train.shape\n",
    "print 'X test shape:'\n",
    "print X_test.shape\n",
    "\n",
    "print 'X train sample:'\n",
    "print X_train[:2,]\n",
    "\n",
    "print 'y train shape:'\n",
    "print y_train.shape\n",
    "print 'y test shape:'\n",
    "print y_test.shape\n",
    "\n",
    "print 'y train sample:'\n",
    "print y_train[:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import TimeDistributed, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NTAGS = n_tags\n",
    "NWORDS = n_words\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NWORDS, EMBEDDING_DIM, input_length=SEQUENCE_LEN))\n",
    "model.add(Bidirectional(LSTM(128, dropout=.1, return_sequences=True)))\n",
    "model.add(LSTM(128, dropout=.1, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(NTAGS, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not CACHED:\n",
    "    for i in range(N_EPOCHS):\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=1,\n",
    "                            verbose=1,\n",
    "                            validation_split=0.1)\n",
    "        model.save('../models/pos_tag_normal')\n",
    "else:\n",
    "    model = load_model('../models/pos_tagging_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20086/20086 [==============================] - 52s    \n",
      "('Test score:', 0.2370081886524498)\n",
      "('Test accuracy:', 0.94630389030528328)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extracts all kind of features\n",
    "\n",
    "See that paper: http://nlp.lsi.upc.edu/papers/gimenez03.pdf\n",
    "\n",
    "and that one http://www.lsi.upc.es/~nlp/SVMTool/lrec2004-gm.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['n_gram_1', 'n_gram_1_lag1', 'n_gram_1_lag2', 'n_gram_2', 'n_gram_2_lag1', 'n_gram_2_lag2']\n"
     ]
    }
   ],
   "source": [
    "# BEWARE - INSERTED STUPID MAX HASH \n",
    "\n",
    "import features as ff\n",
    "\n",
    "features = [] \n",
    "feature_names = []\n",
    "\n",
    "for n in [1,2]:\n",
    "    for d in [0,1,2]:\n",
    "        f = ff.n_grams(n, 10, d)\n",
    "        features.append(f)\n",
    "\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO: Same thing for PREVIOUS POS TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Sentence type\n",
    "ignored_char = [',', '-', '#', '%', '$', '&', '*', '@']\n",
    "\n",
    "ends_exc = ff.sentence_ends('!',ignored_char)\n",
    "features.append(ends_exc)\n",
    "\n",
    "ends_question = ff.sentence_ends('?',ignored_char)\n",
    "features.append(ends_question)\n",
    "\n",
    "ends_dot = ff.sentence_ends('.',ignored_char)\n",
    "features.append(ends_dot)\n",
    "\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Prefixes and Suffixes\n",
    "# for n in [1,2,3]:\n",
    "#     for pref in [True, False]:\n",
    "#         features.append(ends_exc)\n",
    "#         name = 'prefix' if pref else 'suffix'\n",
    "#         name += '_' + str(n)\n",
    "#         feature_names.append(name)\n",
    "\n",
    "# print len(features)\n",
    "# print feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts the Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gets the activations for the hidden states\n",
      "Reshapes\n",
      "Done\n",
      "states shape: (20086, 12800)\n",
      "config: {'input_size': 50, 'states_struct': [('Bidirectional', 50, 256)]}\n"
     ]
    }
   ],
   "source": [
    "import extractor\n",
    "reload(extractor)\n",
    "\n",
    "ex=extractor.Extractor(model)\n",
    "states, nn_config = ex.run_for_layer('Bidirectional', X_test)\n",
    "\n",
    "print 'states shape:', states.shape\n",
    "print 'config:',nn_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature scores\n",
      "Running feature 0 out of 1\n",
      "Added features ['n_gram_0', 'n_gram_1', 'n_gram_2', 'n_gram_3', 'n_gram_4', '...']\n",
      "Tidying...\n",
      "Computed feature matrix, with shape: (20136, 10)\n",
      "Computing score for feature 0: n_gram_0\n",
      "Computing score for feature 1: n_gram_1\n",
      "Computing score for feature 2: n_gram_2\n",
      "Computing score for feature 3: n_gram_3\n",
      "Computing score for feature 4: n_gram_4\n",
      "Computing score for feature 5: n_gram_5\n",
      "Computing score for feature 6: n_gram_6\n",
      "Computing score for feature 7: n_gram_7\n",
      "Computing score for feature 8: n_gram_8\n",
      "Computing score for feature 9: n_gram_9\n"
     ]
    }
   ],
   "source": [
    "import inspector as insp\n",
    "reload(insp)\n",
    "import scores\n",
    "reload(scores)\n",
    "\n",
    "sequence = all_words[N_train:]\n",
    "params = {}\n",
    "for i in range(50):\n",
    "    params[(0,i)] = (scores.Correlation(), i, 0)\n",
    "\n",
    "insp = insp.Inspector(states, nn_config)\n",
    "out = insp.inspect(sequence, features[:1], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12790</th>\n",
       "      <th>12791</th>\n",
       "      <th>12792</th>\n",
       "      <th>12793</th>\n",
       "      <th>12794</th>\n",
       "      <th>12795</th>\n",
       "      <th>12796</th>\n",
       "      <th>12797</th>\n",
       "      <th>12798</th>\n",
       "      <th>12799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032491</td>\n",
       "      <td>0.057243</td>\n",
       "      <td>0.069023</td>\n",
       "      <td>0.046311</td>\n",
       "      <td>0.080630</td>\n",
       "      <td>0.074210</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.042217</td>\n",
       "      <td>0.029495</td>\n",
       "      <td>0.097828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017085</td>\n",
       "      <td>0.015661</td>\n",
       "      <td>0.052999</td>\n",
       "      <td>0.043413</td>\n",
       "      <td>0.049659</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.023939</td>\n",
       "      <td>0.075775</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>0.045156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.283180</td>\n",
       "      <td>0.123163</td>\n",
       "      <td>0.063573</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>0.070403</td>\n",
       "      <td>0.226742</td>\n",
       "      <td>0.410992</td>\n",
       "      <td>0.330819</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>0.241536</td>\n",
       "      <td>0.322075</td>\n",
       "      <td>0.242403</td>\n",
       "      <td>0.065826</td>\n",
       "      <td>0.114902</td>\n",
       "      <td>0.284599</td>\n",
       "      <td>0.441066</td>\n",
       "      <td>0.131421</td>\n",
       "      <td>0.245951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.090895</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.176562</td>\n",
       "      <td>0.178038</td>\n",
       "      <td>0.096006</td>\n",
       "      <td>0.125474</td>\n",
       "      <td>0.259177</td>\n",
       "      <td>0.229808</td>\n",
       "      <td>0.257045</td>\n",
       "      <td>0.263507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227088</td>\n",
       "      <td>0.305888</td>\n",
       "      <td>0.176650</td>\n",
       "      <td>0.261857</td>\n",
       "      <td>0.117274</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.287028</td>\n",
       "      <td>0.121856</td>\n",
       "      <td>0.099642</td>\n",
       "      <td>0.007846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069721</td>\n",
       "      <td>0.028495</td>\n",
       "      <td>0.029548</td>\n",
       "      <td>0.040393</td>\n",
       "      <td>0.027462</td>\n",
       "      <td>0.043828</td>\n",
       "      <td>0.106868</td>\n",
       "      <td>0.027294</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>0.066709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043191</td>\n",
       "      <td>0.067422</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.067046</td>\n",
       "      <td>0.048862</td>\n",
       "      <td>0.087359</td>\n",
       "      <td>0.094623</td>\n",
       "      <td>0.021352</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.043359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160860</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.094638</td>\n",
       "      <td>0.062823</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.298289</td>\n",
       "      <td>0.234565</td>\n",
       "      <td>0.215162</td>\n",
       "      <td>0.168490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151088</td>\n",
       "      <td>0.263169</td>\n",
       "      <td>0.168199</td>\n",
       "      <td>0.196978</td>\n",
       "      <td>0.167279</td>\n",
       "      <td>0.064840</td>\n",
       "      <td>0.283060</td>\n",
       "      <td>0.149965</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.075525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0  0.032491  0.057243  0.069023  0.046311  0.080630  0.074210  0.020371   \n",
       "1  0.283180  0.123163  0.063573  0.116988  0.071565  0.070403  0.226742   \n",
       "2  0.090895  0.152200  0.176562  0.178038  0.096006  0.125474  0.259177   \n",
       "3  0.069721  0.028495  0.029548  0.040393  0.027462  0.043828  0.106868   \n",
       "4  0.160860  0.005712  0.094638  0.062823  0.034226  0.051961  0.298289   \n",
       "\n",
       "      7         8         9        ...        12790     12791     12792  \\\n",
       "0  0.042217  0.029495  0.097828    ...     0.017085  0.015661  0.052999   \n",
       "1  0.410992  0.330819  0.042532    ...     0.021756  0.241536  0.322075   \n",
       "2  0.229808  0.257045  0.263507    ...     0.227088  0.305888  0.176650   \n",
       "3  0.027294  0.074797  0.066709    ...     0.043191  0.067422  0.049583   \n",
       "4  0.234565  0.215162  0.168490    ...     0.151088  0.263169  0.168199   \n",
       "\n",
       "      12793     12794     12795     12796     12797     12798     12799  \n",
       "0  0.043413  0.049659  0.002896  0.023939  0.075775  0.014351  0.045156  \n",
       "1  0.242403  0.065826  0.114902  0.284599  0.441066  0.131421  0.245951  \n",
       "2  0.261857  0.117274  0.023645  0.287028  0.121856  0.099642  0.007846  \n",
       "3  0.067046  0.048862  0.087359  0.094623  0.021352  0.000307  0.043359  \n",
       "4  0.196978  0.167279  0.064840  0.283060  0.149965  0.013304  0.075525  \n",
       "\n",
       "[5 rows x 12800 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
