{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, Headers and Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SENTENCES = 50000\n",
    "TEST_RATIO = .1\n",
    "WINDOW_SIZE = 16\n",
    "N_EPOCHS = 5\n",
    "CACHED = False\n",
    "N_STATES = 16\n",
    "SAMPLES_VERIFY = 8\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "FOLDER_OUT = 'Boolean-' + str(datetime.datetime.today())\n",
    "if not os.path.exists(FOLDER_OUT):\n",
    "    os.makedirs(FOLDER_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "np.random.seed(55555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding\n",
      "Total vocabulary len_sequence:  4\n",
      "(5000,)\n",
      "[array([3, 4, 2, 1, 2, 4, 3, 1, 3, 1, 3, 4, 2, 4, 2, 4, 3])\n",
      " array([3, 1, 2, 1, 2, 4, 2, 1, 3, 4, 3, 4, 3, 4, 3, 4, 2, 4, 3, 1, 2, 1, 3,\n",
      "       1, 3, 4, 3, 4, 3, 4, 3, 1, 2, 4, 3, 1, 2, 1, 3])\n",
      " array([3, 1, 2, 1, 3, 4, 2])\n",
      " array([3, 4, 2, 1, 2, 4, 2, 1, 3, 4, 2, 1, 3, 1, 3, 4, 3, 4, 2, 4, 2, 4, 3,\n",
      "       1, 2])\n",
      " array([3, 1, 3, 1, 2, 4, 2, 4, 2]) array([3, 4, 3, 1, 3, 4, 2, 4, 3])\n",
      " array([2, 4, 2, 1, 3, 4, 2, 1, 3, 4, 2, 4, 2, 4, 3, 4, 3, 4, 3, 1, 3, 4, 3,\n",
      "       4, 3, 1, 3, 4, 3, 4, 2, 1, 2, 1, 2])\n",
      " array([2, 1, 2, 4, 2, 4, 2, 4, 3, 1, 3, 4, 3])\n",
      " array([2, 1, 2, 4, 2, 4, 3, 4, 3, 1, 3, 1, 2, 1, 3, 1, 3, 4, 3, 4, 3, 4, 2,\n",
      "       1, 2, 4, 3, 1, 2, 4, 2, 4, 3, 1, 2, 1, 3, 1, 3])\n",
      " array([3, 4, 3, 1, 2, 1, 3, 1, 2, 1, 2, 4, 2, 1, 3])]\n",
      "True\n",
      "41\n",
      "(5000,)\n",
      "[1 1 0 ..., 0 0 1]\n",
      "(0, 1)\n",
      "{'1': 3, '0': 2, '|': 4, 'X': 0, '&': 1}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils.preprocess as pre\n",
    "reload(pre)\n",
    "\n",
    "input_file = 'boolean.csv'\n",
    "df = pd.read_csv(input_file, dtype={'sequence': object})\n",
    "\n",
    "test_split = 0.5\n",
    "train_size = int(len(df) * (1 - test_split))\n",
    "\n",
    "_, char2int, int2char = pre.encode(''.join(df['sequence']))\n",
    "\n",
    "\n",
    "char2int = dict((key, value + 1) for (key, value) in char2int.items())\n",
    "int2char = dict((key + 1, value) for (key, value) in int2char.items())\n",
    "int2char[0] = 'X'\n",
    "char2int['X'] = 0\n",
    "\n",
    "df['sequence'] = df['sequence'].apply(lambda x: np.array([char2int[e] for e in x]))\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "X_train = np.array(df['sequence'].values[:train_size])\n",
    "y_train = np.array(df['target'].values[:train_size])\n",
    "X_test = np.array(df['sequence'].values[train_size:])\n",
    "y_test = np.array(df['target'].values[train_size:])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[:10])\n",
    "\n",
    "\n",
    "print(all([item.size%2==1 for item in X_train]))\n",
    "\n",
    "print(max([item.size for item in X_train]))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train)\n",
    "print(min(y_train), max(y_train))\n",
    "print (char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test before padding : [ array([2, 4, 2, 4, 3, 4, 3, 1, 2, 4, 3, 4, 2, 1, 3, 4, 3, 1, 3, 4, 2, 4, 2,\n",
      "       4, 3, 4, 2, 1, 2, 4, 2, 4, 2, 4, 3])\n",
      " array([3, 4, 3, 1, 2, 4, 3, 1, 3, 1, 2, 1, 3, 4, 2, 4, 2, 4, 3, 4, 2, 4, 2,\n",
      "       1, 3, 1, 2, 1, 3, 1, 3, 4, 2, 1, 3, 4, 2])\n",
      " array([2, 1, 2, 4, 3, 1, 2, 1, 2, 4, 3, 4, 2, 4, 2, 1, 2, 1, 3, 4, 3, 1, 2,\n",
      "       1, 3, 1, 2])\n",
      " array([3, 1, 2, 1, 2, 1, 3])\n",
      " array([3, 1, 2, 4, 3, 4, 3, 1, 3, 1, 3, 4, 3, 1, 3, 4, 2, 1, 3, 4, 2])\n",
      " array([3, 4, 3, 1, 3, 4, 2, 1, 2, 1, 3, 4, 2, 1, 2, 1, 2])\n",
      " array([2, 4, 3, 1, 2, 4, 3, 1, 3, 4, 3, 1, 3, 1, 2, 4, 3, 1, 3, 1, 2, 1, 3,\n",
      "       4, 3, 1, 2, 4, 2, 4, 3, 1, 3])\n",
      " array([2, 1, 2, 4, 2, 4, 2, 1, 3, 4, 3, 4, 3, 1, 3, 1, 2, 1, 2, 1, 3, 1, 2,\n",
      "       1, 2, 4, 2, 1, 2, 1, 3, 4, 3])\n",
      " array([3, 4, 2, 1, 3, 4, 3, 1, 2, 1, 3, 4, 3, 4, 2, 1, 2, 1, 3])\n",
      " array([2, 1, 2, 4, 3, 1, 2, 4, 3, 4, 3, 1, 3, 4, 3, 1, 3, 1, 2, 1, 3, 4, 3,\n",
      "       1, 2, 1, 3, 4, 2, 4, 2, 1, 2, 1, 2, 4, 3, 1, 3])] \n",
      "X_test after padding : [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 2 4 3 4 3 1 2 4 3 4 2 1 3 4 3 1 3 4 2 4\n",
      "  2 4 3 4 2 1 2 4 2 4 2 4 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 3 1 2 4 3 1 3 1 2 1 3 4 2 4 2 4 3 4 2 4 2 1\n",
      "  3 1 2 1 3 1 3 4 2 1 3 4 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 4 3 1 2 1 2 4 3 4 2 4\n",
      "  2 1 2 1 3 4 3 1 2 1 3 1 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 3 1 2 1 2 1 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 2 4 3 4 3 1\n",
      "  3 1 3 4 3 1 3 4 2 1 3 4 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 3 1\n",
      "  3 4 2 1 2 1 3 4 2 1 2 1 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 4 3 1 2 4 3 1 3 4 3 1 3 1 2 4 3 1 3 1\n",
      "  2 1 3 4 3 1 2 4 2 4 3 1 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 4 2 4 2 1 3 4 3 4 3 1 3 1 2 1 2 1\n",
      "  3 1 2 1 2 4 2 1 2 1 3 4 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 2 1 3 4\n",
      "  3 1 2 1 3 4 3 4 2 1 2 1 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 1 2 4 3 1 2 4 3 4 3 1 3 4 3 1 3 1 2 1 3 4 3 1 2 1\n",
      "  3 4 2 4 2 1 2 1 2 4 3 1 3]] \n"
     ]
    }
   ],
   "source": [
    "# truncate and pad input sequences\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_length = 50\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "\n",
    "print(\"X_test before padding : {} \".format(X_test[:10]))\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)\n",
    "print(\"X_test after padding : {} \".format(X_test[:10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_flat = X_train.flatten()\n",
    "X_train = keras.utils.to_categorical(X_train_flat)\n",
    "X_train = X_train.reshape(5000,max_length,len(char2int))\n",
    "\n",
    "X_test_flat = X_test.flatten()\n",
    "X_test = keras.utils.to_categorical(X_test_flat)\n",
    "X_test = X_test.reshape(5000,max_length,len(char2int))\n",
    "\n",
    "# y_train = y_train.flatten()\n",
    "# y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "# y_test = y_test.flatten()\n",
    "# y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "X: (5000, 50, 5)\n",
      "y: (5000,)\n",
      "Test data:\n",
      "X: (5000, 50, 5)\n",
      "y: (5000,)\n"
     ]
    }
   ],
   "source": [
    "print \"Training data:\"\n",
    "print \"X:\", X_train.shape\n",
    "print \"y:\", y_train.shape\n",
    "\n",
    "print \"Test data:\"\n",
    "print \"X:\", X_test.shape\n",
    "print \"y:\", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM,SimpleRNN\n",
    "from keras.layers import Lambda\n",
    "from keras import regularizers\n",
    "\n",
    "from controllers.mylstm_legacy import MYLSTM\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "in_dim = X_train.shape[1:]\n",
    "# out_dim = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(N_STATES, return_sequences=True,\n",
    "                         stateful=False,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         input_shape=in_dim))\n",
    "model.add(Lambda(lambda x: x[:,-1, :]))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (10, 50, 16)              1408      \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (10, 16)                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (10, 1)                   17        \n",
      "=================================================================\n",
      "Total params: 1,425\n",
      "Trainable params: 1,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 55s - loss: 0.3298 - acc: 0.8626    \n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 55s - loss: 0.2118 - acc: 0.9278    \n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 54s - loss: 0.1545 - acc: 0.9468    \n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 55s - loss: 0.1018 - acc: 0.9676    \n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 55s - loss: 0.0746 - acc: 0.9798    \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from controllers.mylstm_legacy import MYLSTM\n",
    "\n",
    "if not CACHED:\n",
    "    model.summary()\n",
    "    model.fit(X_train, y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        shuffle=False)\n",
    "    model.save('models/boolean.h5')\n",
    "else:\n",
    "    model = load_model('models/boolean.h5')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.54%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "model.reset_states()\n",
    "scores = model.evaluate(X_test, y_test, verbose=0, batch_size=BATCH_SIZE)\n",
    "\n",
    "import pickle\n",
    "pickle.dump((X_test, y_test), open(\"test_data_boolean.pkl\", \"wb\"))\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "model.save('boolean_'+str(datetime.datetime.today())+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import features as feat\n",
    "reload(feat)\n",
    "\n",
    "X_test_sequence = [int2char[i] for i in X_test_flat]\n",
    "\n",
    "bool_fsm_states = feat.bool_fsm_states(char2int)\n",
    "\n",
    "features = [bool_fsm_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating feature scores\n",
      "Running feature 0 out of 1\n",
      "250000\n",
      "Added features ['S0', 'S1', 'S2', 'S3', 'S4', '...']\n",
      "Tidying...\n",
      "Computed feature matrix, with shape: (250000, 7)\n",
      "Snippet of the features\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX0|1&0|0|0\n",
      "['S0', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.]]\n",
      "Features for test sequence:\n",
      "['S0', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']\n",
      "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "reload(feat)\n",
    "\n",
    "feature_frame_x = feat.FeatureFrame(features, X_test_sequence)\n",
    "feature_frame_x.extract()\n",
    "\n",
    "print'Features for test sequence:'\n",
    "print feature_frame_x.names\n",
    "print feature_frame_x.values[:15,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEWARE _ ONLY SUPPORTS CONSECUTIVE LAYER IDS STARTING AT 0\n",
      "Creates spy models\n",
      "... for id 0 : <keras.layers.recurrent.LSTM object at 0x11b5e2c50>\n",
      "Gets the activations for the hidden states\n",
      "Gets structure\n",
      "Gets offets\n",
      "WARNING +++ NOT SUITABLE FOR NON_FORWARD LAYERS\n",
      "Gets structure\n",
      "states shape: (5000, 800)\n",
      "\n",
      "config: [('<keras.layers.recurrent.LSTM object at 0x11b5e2c50>', 50, 16)]\n",
      "offets: {(0, 27): 27, (0, 47): 47, (0, 20): 20, (0, 14): 14, (0, 7): 7, (0, 49): 49, (0, 43): 43, (0, 16): 16, (0, 10): 10, (0, 36): 36, (0, 3): 3, (0, 28): 28, (0, 32): 32, (0, 21): 21, (0, 15): 15, (0, 24): 24, (0, 44): 44, (0, 17): 17, (0, 11): 11, (0, 37): 37, (0, 4): 4, (0, 40): 40, (0, 29): 29, (0, 33): 33, (0, 22): 22, (0, 0): 0, (0, 25): 25, (0, 45): 45, (0, 18): 18, (0, 12): 12, (0, 38): 38, (0, 5): 5, (0, 41): 41, (0, 30): 30, (0, 8): 8, (0, 34): 34, (0, 23): 23, (0, 1): 1, (0, 26): 26, (0, 46): 46, (0, 19): 19, (0, 13): 13, (0, 39): 39, (0, 6): 6, (0, 48): 48, (0, 42): 42, (0, 31): 31, (0, 9): 9, (0, 35): 35, (0, 2): 2}\n"
     ]
    }
   ],
   "source": [
    "import extractor\n",
    "reload(extractor)\n",
    "\n",
    "ex=extractor.Extractor(model, [0])\n",
    "states = ex.get_states(X_test, batch_size=BATCH_SIZE, unshuffle=True)\n",
    "\n",
    "nn_config = ex.get_structure()\n",
    "nn_offsets = ex.get_offets()\n",
    "\n",
    "import pickle\n",
    "pickle.dump(states, open(\"states_boolean.pkl\", \"wb\"))\n",
    "\n",
    "print 'states shape:', states.shape\n",
    "print ''\n",
    "print 'config:', nn_config\n",
    "print 'offets:', nn_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot activations TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspects - correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#states_resized = np.zeros((feature_frame_x.values.shape[0], N_STATES))\n",
    "\n",
    "#for s in range(N_STATES):\n",
    "#    states_resized[:,s] = np.hstack( [ states[:, t+s] for t in range(0, states.shape[1], N_STATES)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing attribution scores\n",
      "Feture matrix dimensions: (250000, 7)\n",
      "States dimensions: (5000, 800)\n",
      "Computing score for feature 0: S0\n",
      "Layer 0\n",
      "Timestep 0\n",
      "Scoring neurons 0 to 15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature has 249951 rows, while states has 5000 rows",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-85f70bd4e696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minsp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInspector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_offsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmi_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_frame_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ian.huang/Documents/Projects/deep-neural-inspector/src/inspector.pyc\u001b[0m in \u001b[0;36minspect\u001b[0;34m(self, nn_states, feature_frame, score_obj)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0;31m# Does the maths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_f\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ian.huang/Documents/Projects/deep-neural-inspector/src/scores.pyc\u001b[0m in \u001b[0;36mscore_cell\u001b[0;34m(self, feat_values, states)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_neuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_neuron\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_neuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ian.huang/Documents/Projects/deep-neural-inspector/src/scores.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feature, states)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ian.huang/Documents/Projects/deep-neural-inspector/src/scores.pyc\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, feature, states)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Feature has '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' rows, while '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0;34m'states has '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' rows'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature has 249951 rows, while states has 5000 rows"
     ]
    }
   ],
   "source": [
    "import scores\n",
    "import inspector as ip\n",
    "\n",
    "insp = ip.Inspector(nn_config, nn_offsets)\n",
    "mi_scores, names = insp.inspect(states, feature_frame_x, scores.Correlation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
